{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fakE3ZcHHGXd"
      },
      "source": [
        "#**Medical NER using BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df-IX0hEKl0N",
        "outputId": "8e520f99-57ef-44b8-d2b1-adc597ebd9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeDLKTYHDvys"
      },
      "source": [
        "##**Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TW_356VDvyu"
      },
      "outputs": [],
      "source": [
        "# https://figshare.com/articles/dataset/MACCROBAT2018/9764942\n",
        "# https://brat.nlplab.org/standoff.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj21Um6uxIAG",
        "outputId": "4373cc47-3c69-41e3-feb2-89cce5005b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eJHereDQJW-mJ3AZaMrzuM6i-Yv2kpD1\n",
            "To: /content/MACCROBAT2018.zip\n",
            "100% 1.06M/1.06M [00:00<00:00, 52.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1eJHereDQJW-mJ3AZaMrzuM6i-Yv2kpD1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twBlZMBj6ghQ",
        "outputId": "b4c5e4b3-4a05-4a93-a8c9-8b6f8a097d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘MACCROBAT2018’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir MACCROBAT2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMF3fdLA6VT2",
        "outputId": "203ce88b-5649-418e-c2eb-e827b0d377f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./MACCROBAT2018.zip\n",
            "  inflating: ./MACCROBAT2018/15939911.ann  \n",
            "  inflating: ./MACCROBAT2018/15939911.txt  \n",
            "  inflating: ./MACCROBAT2018/16778410.ann  \n",
            "  inflating: ./MACCROBAT2018/16778410.txt  \n",
            "  inflating: ./MACCROBAT2018/17803823.ann  \n",
            "  inflating: ./MACCROBAT2018/17803823.txt  \n",
            "  inflating: ./MACCROBAT2018/18236639.ann  \n",
            "  inflating: ./MACCROBAT2018/18236639.txt  \n",
            "  inflating: ./MACCROBAT2018/18258107.ann  \n",
            "  inflating: ./MACCROBAT2018/18258107.txt  \n",
            "  inflating: ./MACCROBAT2018/18416479.ann  \n",
            "  inflating: ./MACCROBAT2018/18416479.txt  \n",
            "  inflating: ./MACCROBAT2018/18561524.ann  \n",
            "  inflating: ./MACCROBAT2018/18561524.txt  \n",
            "  inflating: ./MACCROBAT2018/18666334.ann  \n",
            "  inflating: ./MACCROBAT2018/18666334.txt  \n",
            "  inflating: ./MACCROBAT2018/18787726.ann  \n",
            "  inflating: ./MACCROBAT2018/18787726.txt  \n",
            "  inflating: ./MACCROBAT2018/18815636.ann  \n",
            "  inflating: ./MACCROBAT2018/18815636.txt  \n",
            "  inflating: ./MACCROBAT2018/19009665.ann  \n",
            "  inflating: ./MACCROBAT2018/19009665.txt  \n",
            "  inflating: ./MACCROBAT2018/19214295.ann  \n",
            "  inflating: ./MACCROBAT2018/19214295.txt  \n",
            "  inflating: ./MACCROBAT2018/19307547.ann  \n",
            "  inflating: ./MACCROBAT2018/19307547.txt  \n",
            "  inflating: ./MACCROBAT2018/19610147.ann  \n",
            "  inflating: ./MACCROBAT2018/19610147.txt  \n",
            "  inflating: ./MACCROBAT2018/19816630.ann  \n",
            "  inflating: ./MACCROBAT2018/19816630.txt  \n",
            "  inflating: ./MACCROBAT2018/19860006.ann  \n",
            "  inflating: ./MACCROBAT2018/19860006.txt  \n",
            "  inflating: ./MACCROBAT2018/19860007.ann  \n",
            "  inflating: ./MACCROBAT2018/19860007.txt  \n",
            "  inflating: ./MACCROBAT2018/19860925.ann  \n",
            "  inflating: ./MACCROBAT2018/19860925.txt  \n",
            "  inflating: ./MACCROBAT2018/20146086.ann  \n",
            "  inflating: ./MACCROBAT2018/20146086.txt  \n",
            "  inflating: ./MACCROBAT2018/20671919.ann  \n",
            "  inflating: ./MACCROBAT2018/20671919.txt  \n",
            "  inflating: ./MACCROBAT2018/20977862.ann  \n",
            "  inflating: ./MACCROBAT2018/20977862.txt  \n",
            "  inflating: ./MACCROBAT2018/21067996.ann  \n",
            "  inflating: ./MACCROBAT2018/21067996.txt  \n",
            "  inflating: ./MACCROBAT2018/21129213.ann  \n",
            "  inflating: ./MACCROBAT2018/21129213.txt  \n",
            "  inflating: ./MACCROBAT2018/21254744.ann  \n",
            "  inflating: ./MACCROBAT2018/21254744.txt  \n",
            "  inflating: ./MACCROBAT2018/21308977.ann  \n",
            "  inflating: ./MACCROBAT2018/21308977.txt  \n",
            "  inflating: ./MACCROBAT2018/21477357.ann  \n",
            "  inflating: ./MACCROBAT2018/21477357.txt  \n",
            "  inflating: ./MACCROBAT2018/21505579.ann  \n",
            "  inflating: ./MACCROBAT2018/21505579.txt  \n",
            "  inflating: ./MACCROBAT2018/21527041.ann  \n",
            "  inflating: ./MACCROBAT2018/21527041.txt  \n",
            "  inflating: ./MACCROBAT2018/21672201.ann  \n",
            "  inflating: ./MACCROBAT2018/21672201.txt  \n",
            "  inflating: ./MACCROBAT2018/21720478.ann  \n",
            "  inflating: ./MACCROBAT2018/21720478.txt  \n",
            "  inflating: ./MACCROBAT2018/21923918.ann  \n",
            "  inflating: ./MACCROBAT2018/21923918.txt  \n",
            "  inflating: ./MACCROBAT2018/22218279.ann  \n",
            "  inflating: ./MACCROBAT2018/22218279.txt  \n",
            "  inflating: ./MACCROBAT2018/22514576.ann  \n",
            "  inflating: ./MACCROBAT2018/22514576.txt  \n",
            "  inflating: ./MACCROBAT2018/22515939.ann  \n",
            "  inflating: ./MACCROBAT2018/22515939.txt  \n",
            "  inflating: ./MACCROBAT2018/22520024.ann  \n",
            "  inflating: ./MACCROBAT2018/22520024.txt  \n",
            "  inflating: ./MACCROBAT2018/22665582.ann  \n",
            "  inflating: ./MACCROBAT2018/22665582.txt  \n",
            "  inflating: ./MACCROBAT2018/22719160.ann  \n",
            "  inflating: ./MACCROBAT2018/22719160.txt  \n",
            "  inflating: ./MACCROBAT2018/22781096.ann  \n",
            "  inflating: ./MACCROBAT2018/22781096.txt  \n",
            "  inflating: ./MACCROBAT2018/22791498.ann  \n",
            "  inflating: ./MACCROBAT2018/22791498.txt  \n",
            "  inflating: ./MACCROBAT2018/22814979.ann  \n",
            "  inflating: ./MACCROBAT2018/22814979.txt  \n",
            "  inflating: ./MACCROBAT2018/23033875.ann  \n",
            "  inflating: ./MACCROBAT2018/23033875.txt  \n",
            "  inflating: ./MACCROBAT2018/23035161.ann  \n",
            "  inflating: ./MACCROBAT2018/23035161.txt  \n",
            "  inflating: ./MACCROBAT2018/23076693.ann  \n",
            "  inflating: ./MACCROBAT2018/23076693.txt  \n",
            "  inflating: ./MACCROBAT2018/23077697.ann  \n",
            "  inflating: ./MACCROBAT2018/23077697.txt  \n",
            "  inflating: ./MACCROBAT2018/23124805.ann  \n",
            "  inflating: ./MACCROBAT2018/23124805.txt  \n",
            "  inflating: ./MACCROBAT2018/23155491.ann  \n",
            "  inflating: ./MACCROBAT2018/23155491.txt  \n",
            "  inflating: ./MACCROBAT2018/23242090.ann  \n",
            "  inflating: ./MACCROBAT2018/23242090.txt  \n",
            "  inflating: ./MACCROBAT2018/23312850.ann  \n",
            "  inflating: ./MACCROBAT2018/23312850.txt  \n",
            "  inflating: ./MACCROBAT2018/23468586.ann  \n",
            "  inflating: ./MACCROBAT2018/23468586.txt  \n",
            "  inflating: ./MACCROBAT2018/23678274.ann  \n",
            "  inflating: ./MACCROBAT2018/23678274.txt  \n",
            "  inflating: ./MACCROBAT2018/23864579.ann  \n",
            "  inflating: ./MACCROBAT2018/23864579.txt  \n",
            "  inflating: ./MACCROBAT2018/23897372.ann  \n",
            "  inflating: ./MACCROBAT2018/23897372.txt  \n",
            "  inflating: ./MACCROBAT2018/24043987.ann  \n",
            "  inflating: ./MACCROBAT2018/24043987.txt  \n",
            "  inflating: ./MACCROBAT2018/24161539.ann  \n",
            "  inflating: ./MACCROBAT2018/24161539.txt  \n",
            "  inflating: ./MACCROBAT2018/24294397.ann  \n",
            "  inflating: ./MACCROBAT2018/24294397.txt  \n",
            "  inflating: ./MACCROBAT2018/24518095.ann  \n",
            "  inflating: ./MACCROBAT2018/24518095.txt  \n",
            "  inflating: ./MACCROBAT2018/24526194.ann  \n",
            "  inflating: ./MACCROBAT2018/24526194.txt  \n",
            "  inflating: ./MACCROBAT2018/24654246.ann  \n",
            "  inflating: ./MACCROBAT2018/24654246.txt  \n",
            "  inflating: ./MACCROBAT2018/24781756.ann  \n",
            "  inflating: ./MACCROBAT2018/24781756.txt  \n",
            "  inflating: ./MACCROBAT2018/24898994.ann  \n",
            "  inflating: ./MACCROBAT2018/24898994.txt  \n",
            "  inflating: ./MACCROBAT2018/24957905.ann  \n",
            "  inflating: ./MACCROBAT2018/24957905.txt  \n",
            "  inflating: ./MACCROBAT2018/25023062.ann  \n",
            "  inflating: ./MACCROBAT2018/25023062.txt  \n",
            "  inflating: ./MACCROBAT2018/25024632.ann  \n",
            "  inflating: ./MACCROBAT2018/25024632.txt  \n",
            "  inflating: ./MACCROBAT2018/25139918.ann  \n",
            "  inflating: ./MACCROBAT2018/25139918.txt  \n",
            "  inflating: ./MACCROBAT2018/25155594.ann  \n",
            "  inflating: ./MACCROBAT2018/25155594.txt  \n",
            "  inflating: ./MACCROBAT2018/25210224.ann  \n",
            "  inflating: ./MACCROBAT2018/25210224.txt  \n",
            "  inflating: ./MACCROBAT2018/25246819.ann  \n",
            "  inflating: ./MACCROBAT2018/25246819.txt  \n",
            "  inflating: ./MACCROBAT2018/25293719.ann  \n",
            "  inflating: ./MACCROBAT2018/25293719.txt  \n",
            "  inflating: ./MACCROBAT2018/25295501.ann  \n",
            "  inflating: ./MACCROBAT2018/25295501.txt  \n",
            "  inflating: ./MACCROBAT2018/25370695.ann  \n",
            "  inflating: ./MACCROBAT2018/25370695.txt  \n",
            "  inflating: ./MACCROBAT2018/25410034.ann  \n",
            "  inflating: ./MACCROBAT2018/25410034.txt  \n",
            "  inflating: ./MACCROBAT2018/25410883.ann  \n",
            "  inflating: ./MACCROBAT2018/25410883.txt  \n",
            "  inflating: ./MACCROBAT2018/25572898.ann  \n",
            "  inflating: ./MACCROBAT2018/25572898.txt  \n",
            "  inflating: ./MACCROBAT2018/25661749.ann  \n",
            "  inflating: ./MACCROBAT2018/25661749.txt  \n",
            "  inflating: ./MACCROBAT2018/25721834.ann  \n",
            "  inflating: ./MACCROBAT2018/25721834.txt  \n",
            "  inflating: ./MACCROBAT2018/25743872.ann  \n",
            "  inflating: ./MACCROBAT2018/25743872.txt  \n",
            "  inflating: ./MACCROBAT2018/25759562.ann  \n",
            "  inflating: ./MACCROBAT2018/25759562.txt  \n",
            "  inflating: ./MACCROBAT2018/25793030.ann  \n",
            "  inflating: ./MACCROBAT2018/25793030.txt  \n",
            "  inflating: ./MACCROBAT2018/25853982.ann  \n",
            "  inflating: ./MACCROBAT2018/25853982.txt  \n",
            "  inflating: ./MACCROBAT2018/25858931.ann  \n",
            "  inflating: ./MACCROBAT2018/25858931.txt  \n",
            "  inflating: ./MACCROBAT2018/25884600.ann  \n",
            "  inflating: ./MACCROBAT2018/25884600.txt  \n",
            "  inflating: ./MACCROBAT2018/25926582.ann  \n",
            "  inflating: ./MACCROBAT2018/25926582.txt  \n",
            "  inflating: ./MACCROBAT2018/25934795.ann  \n",
            "  inflating: ./MACCROBAT2018/25934795.txt  \n",
            "  inflating: ./MACCROBAT2018/26106249.ann  \n",
            "  inflating: ./MACCROBAT2018/26106249.txt  \n",
            "  inflating: ./MACCROBAT2018/26175648.ann  \n",
            "  inflating: ./MACCROBAT2018/26175648.txt  \n",
            "  inflating: ./MACCROBAT2018/26216058.ann  \n",
            "  inflating: ./MACCROBAT2018/26216058.txt  \n",
            "  inflating: ./MACCROBAT2018/26228535.ann  \n",
            "  inflating: ./MACCROBAT2018/26228535.txt  \n",
            "  inflating: ./MACCROBAT2018/26257516.ann  \n",
            "  inflating: ./MACCROBAT2018/26257516.txt  \n",
            "  inflating: ./MACCROBAT2018/26264228.ann  \n",
            "  inflating: ./MACCROBAT2018/26264228.txt  \n",
            "  inflating: ./MACCROBAT2018/26266396.ann  \n",
            "  inflating: ./MACCROBAT2018/26266396.txt  \n",
            "  inflating: ./MACCROBAT2018/26285706.ann  \n",
            "  inflating: ./MACCROBAT2018/26285706.txt  \n",
            "  inflating: ./MACCROBAT2018/26309459.ann  \n",
            "  inflating: ./MACCROBAT2018/26309459.txt  \n",
            "  inflating: ./MACCROBAT2018/26313770.ann  \n",
            "  inflating: ./MACCROBAT2018/26313770.txt  \n",
            "  inflating: ./MACCROBAT2018/26327988.ann  \n",
            "  inflating: ./MACCROBAT2018/26327988.txt  \n",
            "  inflating: ./MACCROBAT2018/26336183.ann  \n",
            "  inflating: ./MACCROBAT2018/26336183.txt  \n",
            "  inflating: ./MACCROBAT2018/26350418.ann  \n",
            "  inflating: ./MACCROBAT2018/26350418.txt  \n",
            "  inflating: ./MACCROBAT2018/26361431.ann  \n",
            "  inflating: ./MACCROBAT2018/26361431.txt  \n",
            "  inflating: ./MACCROBAT2018/26361640.ann  \n",
            "  inflating: ./MACCROBAT2018/26361640.txt  \n",
            "  inflating: ./MACCROBAT2018/26395443.ann  \n",
            "  inflating: ./MACCROBAT2018/26395443.txt  \n",
            "  inflating: ./MACCROBAT2018/26405496.ann  \n",
            "  inflating: ./MACCROBAT2018/26405496.txt  \n",
            "  inflating: ./MACCROBAT2018/26444414.ann  \n",
            "  inflating: ./MACCROBAT2018/26444414.txt  \n",
            "  inflating: ./MACCROBAT2018/26445413.ann  \n",
            "  inflating: ./MACCROBAT2018/26445413.txt  \n",
            "  inflating: ./MACCROBAT2018/26457578.ann  \n",
            "  inflating: ./MACCROBAT2018/26457578.txt  \n",
            "  inflating: ./MACCROBAT2018/26469535.ann  \n",
            "  inflating: ./MACCROBAT2018/26469535.txt  \n",
            "  inflating: ./MACCROBAT2018/26474553.ann  \n",
            "  inflating: ./MACCROBAT2018/26474553.txt  \n",
            "  inflating: ./MACCROBAT2018/26523273.ann  \n",
            "  inflating: ./MACCROBAT2018/26523273.txt  \n",
            "  inflating: ./MACCROBAT2018/26530965.ann  \n",
            "  inflating: ./MACCROBAT2018/26530965.txt  \n",
            "  inflating: ./MACCROBAT2018/26584481.ann  \n",
            "  inflating: ./MACCROBAT2018/26584481.txt  \n",
            "  inflating: ./MACCROBAT2018/26629302.ann  \n",
            "  inflating: ./MACCROBAT2018/26629302.txt  \n",
            "  inflating: ./MACCROBAT2018/26656340.ann  \n",
            "  inflating: ./MACCROBAT2018/26656340.txt  \n",
            "  inflating: ./MACCROBAT2018/26664317.ann  \n",
            "  inflating: ./MACCROBAT2018/26664317.txt  \n",
            "  inflating: ./MACCROBAT2018/26670309.ann  \n",
            "  inflating: ./MACCROBAT2018/26670309.txt  \n",
            "  inflating: ./MACCROBAT2018/26675562.ann  \n",
            "  inflating: ./MACCROBAT2018/26675562.txt  \n",
            "  inflating: ./MACCROBAT2018/26683938.ann  \n",
            "  inflating: ./MACCROBAT2018/26683938.txt  \n",
            "  inflating: ./MACCROBAT2018/26692730.ann  \n",
            "  inflating: ./MACCROBAT2018/26692730.txt  \n",
            "  inflating: ./MACCROBAT2018/26714786.ann  \n",
            "  inflating: ./MACCROBAT2018/26714786.txt  \n",
            "  inflating: ./MACCROBAT2018/27004009.ann  \n",
            "  inflating: ./MACCROBAT2018/27004009.txt  \n",
            "  inflating: ./MACCROBAT2018/27057898.ann  \n",
            "  inflating: ./MACCROBAT2018/27057898.txt  \n",
            "  inflating: ./MACCROBAT2018/27059701.ann  \n",
            "  inflating: ./MACCROBAT2018/27059701.txt  \n",
            "  inflating: ./MACCROBAT2018/27064109.ann  \n",
            "  inflating: ./MACCROBAT2018/27064109.txt  \n",
            "  inflating: ./MACCROBAT2018/27100441.ann  \n",
            "  inflating: ./MACCROBAT2018/27100441.txt  \n",
            "  inflating: ./MACCROBAT2018/27130218.ann  \n",
            "  inflating: ./MACCROBAT2018/27130218.txt  \n",
            "  inflating: ./MACCROBAT2018/27196481.ann  \n",
            "  inflating: ./MACCROBAT2018/27196481.txt  \n",
            "  inflating: ./MACCROBAT2018/27218632.ann  \n",
            "  inflating: ./MACCROBAT2018/27218632.txt  \n",
            "  inflating: ./MACCROBAT2018/27661040.ann  \n",
            "  inflating: ./MACCROBAT2018/27661040.txt  \n",
            "  inflating: ./MACCROBAT2018/27683825.ann  \n",
            "  inflating: ./MACCROBAT2018/27683825.txt  \n",
            "  inflating: ./MACCROBAT2018/27741115.ann  \n",
            "  inflating: ./MACCROBAT2018/27741115.txt  \n",
            "  inflating: ./MACCROBAT2018/27749582.ann  \n",
            "  inflating: ./MACCROBAT2018/27749582.txt  \n",
            "  inflating: ./MACCROBAT2018/27773410.ann  \n",
            "  inflating: ./MACCROBAT2018/27773410.txt  \n",
            "  inflating: ./MACCROBAT2018/27793101.ann  \n",
            "  inflating: ./MACCROBAT2018/27793101.txt  \n",
            "  inflating: ./MACCROBAT2018/27821134.ann  \n",
            "  inflating: ./MACCROBAT2018/27821134.txt  \n",
            "  inflating: ./MACCROBAT2018/27842595.ann  \n",
            "  inflating: ./MACCROBAT2018/27842595.txt  \n",
            "  inflating: ./MACCROBAT2018/27842605.ann  \n",
            "  inflating: ./MACCROBAT2018/27842605.txt  \n",
            "  inflating: ./MACCROBAT2018/27846860.ann  \n",
            "  inflating: ./MACCROBAT2018/27846860.txt  \n",
            "  inflating: ./MACCROBAT2018/27904130.ann  \n",
            "  inflating: ./MACCROBAT2018/27904130.txt  \n",
            "  inflating: ./MACCROBAT2018/27906105.ann  \n",
            "  inflating: ./MACCROBAT2018/27906105.txt  \n",
            "  inflating: ./MACCROBAT2018/27928148.ann  \n",
            "  inflating: ./MACCROBAT2018/27928148.txt  \n",
            "  inflating: ./MACCROBAT2018/27974938.ann  \n",
            "  inflating: ./MACCROBAT2018/27974938.txt  \n",
            "  inflating: ./MACCROBAT2018/27980261.ann  \n",
            "  inflating: ./MACCROBAT2018/27980261.txt  \n",
            "  inflating: ./MACCROBAT2018/27980272.ann  \n",
            "  inflating: ./MACCROBAT2018/27980272.txt  \n",
            "  inflating: ./MACCROBAT2018/27990013.ann  \n",
            "  inflating: ./MACCROBAT2018/27990013.txt  \n",
            "  inflating: ./MACCROBAT2018/27998312.ann  \n",
            "  inflating: ./MACCROBAT2018/27998312.txt  \n",
            "  inflating: ./MACCROBAT2018/28033278.ann  \n",
            "  inflating: ./MACCROBAT2018/28033278.txt  \n",
            "  inflating: ./MACCROBAT2018/28057913.ann  \n",
            "  inflating: ./MACCROBAT2018/28057913.txt  \n",
            "  inflating: ./MACCROBAT2018/28079821.ann  \n",
            "  inflating: ./MACCROBAT2018/28079821.txt  \n",
            "  inflating: ./MACCROBAT2018/28090049.ann  \n",
            "  inflating: ./MACCROBAT2018/28090049.txt  \n",
            "  inflating: ./MACCROBAT2018/28100235.ann  \n",
            "  inflating: ./MACCROBAT2018/28100235.txt  \n",
            "  inflating: ./MACCROBAT2018/28100279.ann  \n",
            "  inflating: ./MACCROBAT2018/28100279.txt  \n",
            "  inflating: ./MACCROBAT2018/28103924.ann  \n",
            "  inflating: ./MACCROBAT2018/28103924.txt  \n",
            "  inflating: ./MACCROBAT2018/28115731.ann  \n",
            "  inflating: ./MACCROBAT2018/28115731.txt  \n",
            "  inflating: ./MACCROBAT2018/28120581.ann  \n",
            "  inflating: ./MACCROBAT2018/28120581.txt  \n",
            "  inflating: ./MACCROBAT2018/28121940.ann  \n",
            "  inflating: ./MACCROBAT2018/28121940.txt  \n",
            "  inflating: ./MACCROBAT2018/28151860.ann  \n",
            "  inflating: ./MACCROBAT2018/28151860.txt  \n",
            "  inflating: ./MACCROBAT2018/28151882.ann  \n",
            "  inflating: ./MACCROBAT2018/28151882.txt  \n",
            "  inflating: ./MACCROBAT2018/28151916.ann  \n",
            "  inflating: ./MACCROBAT2018/28151916.txt  \n",
            "  inflating: ./MACCROBAT2018/28154281.ann  \n",
            "  inflating: ./MACCROBAT2018/28154281.txt  \n",
            "  inflating: ./MACCROBAT2018/28154287.ann  \n",
            "  inflating: ./MACCROBAT2018/28154287.txt  \n",
            "  inflating: ./MACCROBAT2018/28154669.ann  \n",
            "  inflating: ./MACCROBAT2018/28154669.txt  \n",
            "  inflating: ./MACCROBAT2018/28154700.ann  \n",
            "  inflating: ./MACCROBAT2018/28154700.txt  \n",
            "  inflating: ./MACCROBAT2018/28173879.ann  \n",
            "  inflating: ./MACCROBAT2018/28173879.txt  \n",
            "  inflating: ./MACCROBAT2018/28190872.ann  \n",
            "  inflating: ./MACCROBAT2018/28190872.txt  \n",
            "  inflating: ./MACCROBAT2018/28193213.ann  \n",
            "  inflating: ./MACCROBAT2018/28193213.txt  \n",
            "  inflating: ./MACCROBAT2018/28196820.ann  \n",
            "  inflating: ./MACCROBAT2018/28196820.txt  \n",
            "  inflating: ./MACCROBAT2018/28202862.ann  \n",
            "  inflating: ./MACCROBAT2018/28202862.txt  \n",
            "  inflating: ./MACCROBAT2018/28202865.ann  \n",
            "  inflating: ./MACCROBAT2018/28202865.txt  \n",
            "  inflating: ./MACCROBAT2018/28202869.ann  \n",
            "  inflating: ./MACCROBAT2018/28202869.txt  \n",
            "  inflating: ./MACCROBAT2018/28207542.ann  \n",
            "  inflating: ./MACCROBAT2018/28207542.txt  \n",
            "  inflating: ./MACCROBAT2018/28216610.ann  \n",
            "  inflating: ./MACCROBAT2018/28216610.txt  \n",
            "  inflating: ./MACCROBAT2018/28239141.ann  \n",
            "  inflating: ./MACCROBAT2018/28239141.txt  \n",
            "  inflating: ./MACCROBAT2018/28248858.ann  \n",
            "  inflating: ./MACCROBAT2018/28248858.txt  \n",
            "  inflating: ./MACCROBAT2018/28248891.ann  \n",
            "  inflating: ./MACCROBAT2018/28248891.txt  \n",
            "  inflating: ./MACCROBAT2018/28250304.ann  \n",
            "  inflating: ./MACCROBAT2018/28250304.txt  \n",
            "  inflating: ./MACCROBAT2018/28250406.ann  \n",
            "  inflating: ./MACCROBAT2018/28250406.txt  \n",
            "  inflating: ./MACCROBAT2018/28265107.ann  \n",
            "  inflating: ./MACCROBAT2018/28265107.txt  \n",
            "  inflating: ./MACCROBAT2018/28272214.ann  \n",
            "  inflating: ./MACCROBAT2018/28272214.txt  \n",
            "  inflating: ./MACCROBAT2018/28272235.ann  \n",
            "  inflating: ./MACCROBAT2018/28272235.txt  \n",
            "  inflating: ./MACCROBAT2018/28292056.ann  \n",
            "  inflating: ./MACCROBAT2018/28292056.txt  \n",
            "  inflating: ./MACCROBAT2018/28296749.ann  \n",
            "  inflating: ./MACCROBAT2018/28296749.txt  \n",
            "  inflating: ./MACCROBAT2018/28296775.ann  \n",
            "  inflating: ./MACCROBAT2018/28296775.txt  \n",
            "  inflating: ./MACCROBAT2018/28320420.ann  \n",
            "  inflating: ./MACCROBAT2018/28320420.txt  \n",
            "  inflating: ./MACCROBAT2018/28321070.ann  \n",
            "  inflating: ./MACCROBAT2018/28321070.txt  \n",
            "  inflating: ./MACCROBAT2018/28321071.ann  \n",
            "  inflating: ./MACCROBAT2018/28321071.txt  \n",
            "  inflating: ./MACCROBAT2018/28321073.ann  \n",
            "  inflating: ./MACCROBAT2018/28321073.txt  \n",
            "  inflating: ./MACCROBAT2018/28353556.ann  \n",
            "  inflating: ./MACCROBAT2018/28353556.txt  \n",
            "  inflating: ./MACCROBAT2018/28353558.ann  \n",
            "  inflating: ./MACCROBAT2018/28353558.txt  \n",
            "  inflating: ./MACCROBAT2018/28353561.ann  \n",
            "  inflating: ./MACCROBAT2018/28353561.txt  \n",
            "  inflating: ./MACCROBAT2018/28353569.ann  \n",
            "  inflating: ./MACCROBAT2018/28353569.txt  \n",
            "  inflating: ./MACCROBAT2018/28353588.ann  \n",
            "  inflating: ./MACCROBAT2018/28353588.txt  \n",
            "  inflating: ./MACCROBAT2018/28353596.ann  \n",
            "  inflating: ./MACCROBAT2018/28353596.txt  \n",
            "  inflating: ./MACCROBAT2018/28353604.ann  \n",
            "  inflating: ./MACCROBAT2018/28353604.txt  \n",
            "  inflating: ./MACCROBAT2018/28353613.ann  \n",
            "  inflating: ./MACCROBAT2018/28353613.txt  \n",
            "  inflating: ./MACCROBAT2018/28383413.ann  \n",
            "  inflating: ./MACCROBAT2018/28383413.txt  \n",
            "  inflating: ./MACCROBAT2018/28403086.ann  \n",
            "  inflating: ./MACCROBAT2018/28403086.txt  \n",
            "  inflating: ./MACCROBAT2018/28403092.ann  \n",
            "  inflating: ./MACCROBAT2018/28403092.txt  \n",
            "  inflating: ./MACCROBAT2018/28403099.ann  \n",
            "  inflating: ./MACCROBAT2018/28403099.txt  \n",
            "  inflating: ./MACCROBAT2018/28422883.ann  \n",
            "  inflating: ./MACCROBAT2018/28422883.txt  \n",
            "  inflating: ./MACCROBAT2018/28538413.ann  \n",
            "  inflating: ./MACCROBAT2018/28538413.txt  \n",
            "  inflating: ./MACCROBAT2018/28559815.ann  \n",
            "  inflating: ./MACCROBAT2018/28559815.txt  \n",
            "  inflating: ./MACCROBAT2018/28595573.ann  \n",
            "  inflating: ./MACCROBAT2018/28595573.txt  \n",
            "  inflating: ./MACCROBAT2018/28767567.ann  \n",
            "  inflating: ./MACCROBAT2018/28767567.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip ./MACCROBAT2018.zip -d ./MACCROBAT2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLWt_B-b68PI",
        "outputId": "4391d60b-6dd3-4204-cfc1-003f8b08e12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvogrdlGDvyv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class Preprocessing_Maccrobat:\n",
        "    def __init__(self, dataset_folder, tokenizer):\n",
        "        self.file_ids = [f.split(\".\")[0] for f in os.listdir(dataset_folder) if f.endswith('.txt')]\n",
        "\n",
        "        self.text_files = [f+\".txt\" for f in self.file_ids]\n",
        "        self.anno_files = [f+\".ann\" for f in self.file_ids]\n",
        "\n",
        "        self.num_samples = len(self.file_ids)\n",
        "\n",
        "        self.texts: List[str] = []\n",
        "        for i in range(self.num_samples):\n",
        "            file_path = os.path.join(dataset_folder, self.text_files[i])\n",
        "            with open(file_path, 'r') as f:\n",
        "                self.texts.append(f.read())\n",
        "\n",
        "        self.tags: List[Dict[str, str]] = []\n",
        "        for i in range(self.num_samples):\n",
        "            file_path = os.path.join(dataset_folder, self.anno_files[i])\n",
        "            with open(file_path, 'r') as f:\n",
        "                text_bound_ann = [t.split(\"\\t\") for t in f.read().split(\"\\n\") if t.startswith(\"T\")]\n",
        "                text_bound_lst = []\n",
        "                for text_b in text_bound_ann:\n",
        "                    label = text_b[1].split(\" \")\n",
        "                    try:\n",
        "                        _ = int(label[1])\n",
        "                        _ = int(label[2])\n",
        "                        tag = {\n",
        "                            \"text\": text_b[-1],\n",
        "                            \"label\": label[0],\n",
        "                            \"start\": label[1],\n",
        "                            \"end\": label[2]\n",
        "                        }\n",
        "                        text_bound_lst.append(tag)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                self.tags.append(text_bound_lst)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def process(self) -> Tuple[List[List[str]], List[List[str]]]:\n",
        "        input_texts = []\n",
        "        input_labels = []\n",
        "\n",
        "        for idx in range(self.num_samples):\n",
        "            full_text = self.texts[idx]\n",
        "            tags = self.tags[idx]\n",
        "\n",
        "            label_offset = []\n",
        "            continuous_label_offset = []\n",
        "            for tag in tags:\n",
        "                offset = list(range(int(tag[\"start\"]), int(tag[\"end\"])+1))\n",
        "                label_offset.append(offset) # 345\n",
        "                continuous_label_offset.extend(offset) #  345\n",
        "\n",
        "            all_offset = list(range(len(full_text)))\n",
        "            zero_offset = [offset for offset in all_offset if offset not in continuous_label_offset]\n",
        "            zero_offset = Preprocessing_Maccrobat.find_continuous_ranges(zero_offset) # 012 67\n",
        "\n",
        "            self.tokens = []\n",
        "            self.labels = []\n",
        "            self._merge_offset(full_text, tags, zero_offset, label_offset)\n",
        "            assert len(self.tokens) == len(self.labels), f\"Length of tokens and labels are not equal\"\n",
        "\n",
        "            input_texts.append(self.tokens)\n",
        "            input_labels.append(self.labels)\n",
        "\n",
        "        return input_texts, input_labels\n",
        "\n",
        "    def _merge_offset(self, full_text, tags, zero_offset, label_offset):\n",
        "        # zero: [[0,1,2], [6,7]] label: [[3,4,5]]\n",
        "        i = j = 0\n",
        "        while i < len(zero_offset) and j < len(label_offset):\n",
        "            if zero_offset[i][0] < label_offset[j][0]:\n",
        "                self._add_zero(full_text, zero_offset, i)\n",
        "                i += 1\n",
        "            else:\n",
        "                self._add_label(full_text, label_offset, j, tags)\n",
        "                j += 1\n",
        "\n",
        "        while i < len(zero_offset):\n",
        "            self._add_zero(full_text, zero_offset, i)\n",
        "            i += 1\n",
        "\n",
        "        while j < len(label_offset):\n",
        "            self._add_label(full_text, label_offset, j, tags)\n",
        "            j += 1\n",
        "\n",
        "    def _add_zero(self, full_text, offset, index):\n",
        "        start, *_ ,end =  offset[index] if len(offset[index]) > 1 else (offset[index][0], offset[index][0]+1)\n",
        "        text = full_text[start:end]\n",
        "        text_tokens = self.tokenizer.tokenize(text)\n",
        "\n",
        "        self.tokens.extend(text_tokens)\n",
        "        self.labels.extend(\n",
        "            [\"O\"]*len(text_tokens)\n",
        "        )\n",
        "\n",
        "    def _add_label(self, full_text, offset, index, tags):\n",
        "        start, *_ ,end =  offset[index] if len(offset[index]) > 1 else (offset[index][0], offset[index][0]+1)\n",
        "        text = full_text[start:end]\n",
        "        text_tokens = self.tokenizer.tokenize(text)\n",
        "\n",
        "        self.tokens.extend(text_tokens)\n",
        "        self.labels.extend(\n",
        "            [f\"B-{tags[index]['label']}\"] + [f\"I-{tags[index]['label']}\"]*(len(text_tokens)-1)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def build_label2id(tokens: List[List[str]]):\n",
        "        label2id = {}\n",
        "        id_counter = 0\n",
        "        for token in [token for sublist in tokens for token in sublist]:\n",
        "            if token not in label2id:\n",
        "                label2id[token] = id_counter\n",
        "                id_counter += 1\n",
        "        return label2id\n",
        "\n",
        "    @staticmethod\n",
        "    def find_continuous_ranges(data: List[int]): # [0, 1, 2, 6, 7]\n",
        "        if not data:\n",
        "            return []\n",
        "        ranges = []\n",
        "        start = data[0] # 0\n",
        "        prev = data[0] # 0\n",
        "        for number in data[1:]: # [1, 2, 6, 7]\n",
        "            if number != prev + 1:\n",
        "                ranges.append(list(range(start, prev + 1)))\n",
        "                start = number\n",
        "            prev = number\n",
        "        ranges.append(list(range(start, prev + 1)))\n",
        "        return ranges\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbChgdJBDvyw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "\n",
        "dataset_folder = \"./MACCROBAT2018\"\n",
        "\n",
        "Maccrobat_builder = Preprocessing_Maccrobat(dataset_folder, tokenizer)\n",
        "input_texts, input_labels = Maccrobat_builder.process()\n",
        "\n",
        "label2id = Preprocessing_Maccrobat.build_label2id(input_labels)\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L00L2OBDvyw"
      },
      "source": [
        "##**Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "petkdEIfDvyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "inputs_train, inputs_val, labels_train, labels_val = train_test_split(\n",
        "    input_texts,\n",
        "    input_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oUIPGDkDvyx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "class NER_Dataset(Dataset):\n",
        "    def __init__(self, input_texts, input_labels, tokenizer, label2id, max_len=MAX_LEN):\n",
        "        super().__init__()\n",
        "        self.tokens = input_texts\n",
        "        self.labels = input_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_token = self.tokens[idx]\n",
        "        label_token = [self.label2id[label] for label in self.labels[idx]]\n",
        "\n",
        "        input_token = self.tokenizer.convert_tokens_to_ids(input_token)\n",
        "        attention_mask = [1]*len(input_token)\n",
        "\n",
        "        input_ids = self.pad_and_truncate(input_token,pad_id = self.tokenizer.pad_token_id)\n",
        "        labels = self.pad_and_truncate(label_token,pad_id=0)\n",
        "        attention_mask = self.pad_and_truncate(attention_mask,pad_id=0)\n",
        "        return {\n",
        "            \"input_ids\":torch.as_tensor(input_ids),\n",
        "            \"labels\":torch.as_tensor(labels),\n",
        "            \"attention_mask\":torch.as_tensor(attention_mask)\n",
        "        }\n",
        "\n",
        "    def pad_and_truncate(self, inputs: List[int], pad_id: int):\n",
        "        if len(inputs) < self.max_len:\n",
        "            padded_inputs = inputs + [pad_id] * (self.max_len - len(inputs))\n",
        "        else:\n",
        "            padded_inputs = inputs[:self.max_len]\n",
        "        return padded_inputs\n",
        "\n",
        "    def label2id(self, labels: List[str]):\n",
        "        return [self.label2id[label] for label in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVahTlQhDvyx"
      },
      "outputs": [],
      "source": [
        "train_set = NER_Dataset(inputs_train, labels_train, tokenizer, label2id)\n",
        "val_set = NER_Dataset(inputs_val, labels_val, tokenizer, label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeBJwjyaDvyx"
      },
      "source": [
        "##**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD5TBXEfDvyx",
        "outputId": "aa6de851-7358-4c89-f470-4d0f5f1f06bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at d4data/biomedical-ner-all and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([84]) in the checkpoint and torch.Size([83]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([84, 768]) in the checkpoint and torch.Size([83, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForTokenClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=83, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"d4data/biomedical-ner-all\",\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rso-vNFrDvyy"
      },
      "source": [
        "##**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8i2mwbGOKIm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgIPmqAsDvyy"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    mask = labels != 0\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions[mask], references=labels[mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "MAL9PNPKDvyy",
        "outputId": "1db970ab-37f5-4627-9fe0-3b6a5efb3fb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-52-f104d4976d05>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 06:28, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.743800</td>\n",
              "      <td>1.840967</td>\n",
              "      <td>0.296993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.472900</td>\n",
              "      <td>1.065471</td>\n",
              "      <td>0.585185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.916100</td>\n",
              "      <td>0.777479</td>\n",
              "      <td>0.707451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.650900</td>\n",
              "      <td>0.680812</td>\n",
              "      <td>0.747712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.492300</td>\n",
              "      <td>0.631527</td>\n",
              "      <td>0.760261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.381800</td>\n",
              "      <td>0.611965</td>\n",
              "      <td>0.775599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.309600</td>\n",
              "      <td>0.602531</td>\n",
              "      <td>0.774205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.254600</td>\n",
              "      <td>0.599172</td>\n",
              "      <td>0.786144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.208900</td>\n",
              "      <td>0.607505</td>\n",
              "      <td>0.788322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.178000</td>\n",
              "      <td>0.614869</td>\n",
              "      <td>0.787712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.159000</td>\n",
              "      <td>0.621948</td>\n",
              "      <td>0.801220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.139000</td>\n",
              "      <td>0.628173</td>\n",
              "      <td>0.799651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.123900</td>\n",
              "      <td>0.622207</td>\n",
              "      <td>0.797037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.631116</td>\n",
              "      <td>0.791547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.633567</td>\n",
              "      <td>0.797647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.095800</td>\n",
              "      <td>0.632076</td>\n",
              "      <td>0.795468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.089800</td>\n",
              "      <td>0.635247</td>\n",
              "      <td>0.799041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.087400</td>\n",
              "      <td>0.646403</td>\n",
              "      <td>0.798083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.084100</td>\n",
              "      <td>0.637967</td>\n",
              "      <td>0.799216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.638351</td>\n",
              "      <td>0.800697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=0.43413387358188626, metrics={'train_runtime': 390.7664, 'train_samples_per_second': 8.189, 'train_steps_per_second': 0.512, 'total_flos': 418702245888000.0, 'train_loss': 0.43413387358188626, 'epoch': 20.0})"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"ner-biomedical-maccrobat2018\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=20,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    optim=\"adamw_torch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUlZygpCDvyy"
      },
      "source": [
        "##**Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiQXrzXFa0j3"
      },
      "outputs": [],
      "source": [
        "def inference(sentence, model):\n",
        "    input_token = torch.as_tensor([tokenizer.convert_tokens_to_ids(sentence.split())]).to(\"cuda\")\n",
        "    outputs = model(input_token)\n",
        "    _,preds = torch.max(outputs.logits,-1)\n",
        "    return preds[0].cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zgwHMdPZyk7"
      },
      "outputs": [],
      "source": [
        "def merge_entity(sentence, preds, model):\n",
        "    merged_list =[]\n",
        "    prev_value = None\n",
        "    temp_keys = []\n",
        "\n",
        "    for key,value in zip(sentence.split(),preds):\n",
        "      value = model.config.id2label[value].split(\"-\")[-1]\n",
        "      if value ==\"O\":\n",
        "        if temp_keys:\n",
        "          merged_list.append((prev_value,\", \".join(temp_keys)))\n",
        "          temp_keys = []\n",
        "        merged_list.append((value,key))\n",
        "        prev_value=None\n",
        "      elif value == prev_value:\n",
        "        temp_keys.append(key)\n",
        "      else:\n",
        "        if temp_keys:\n",
        "          merged_list.append((prev_value,\" \".join(temp_keys)))\n",
        "          temp_keys = [key]\n",
        "          prev_value = value\n",
        "    if temp_keys:\n",
        "      merged_list.append((prev_value,\", \".join(temp_keys)))\n",
        "    return merged_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcmzVkIbb095"
      },
      "outputs": [],
      "source": [
        "sentence = \"\"\"A 48 year - old female presented with vaginal bleeding and abnormal Pap smears .\n",
        "Upon diagnosis of invasive non - keratinizing SCC of the cervix ,\n",
        "she underwent a radical hysterectomy with salpingo - oophorectomy\n",
        "which demonstrated positive spread to the pelvic lymph nodes and the parametrium .\n",
        "Pathological examination revealed that the tumour also extensively involved the lower uterine segment .\n",
        "\"\"\"\n",
        "preds = inference(sentence, model)\n",
        "results = merge_entity(sentence, preds, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmD5_h-VcCLb",
        "outputId": "05b1c24e-a02c-4365-e7fa-d6e55ffd9531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('O', 'A'),\n",
              " ('O', 'with'),\n",
              " ('O', 'vaginal'),\n",
              " ('O', 'and'),\n",
              " ('O', 'Pap'),\n",
              " ('O', 'smears'),\n",
              " ('O', '.'),\n",
              " ('O', 'Upon'),\n",
              " ('O', 'diagnosis'),\n",
              " ('O', 'of'),\n",
              " ('O', 'SCC'),\n",
              " ('O', 'of'),\n",
              " ('O', 'the'),\n",
              " ('O', 'cervix'),\n",
              " ('O', ','),\n",
              " ('O', 'she'),\n",
              " ('O', 'underwent'),\n",
              " ('O', 'a'),\n",
              " ('O', 'radical'),\n",
              " ('O', 'with'),\n",
              " ('O', 'which'),\n",
              " ('O', 'demonstrated'),\n",
              " ('O', 'spread'),\n",
              " ('O', 'to'),\n",
              " ('O', 'the'),\n",
              " ('O', 'pelvic'),\n",
              " ('O', 'lymph'),\n",
              " ('O', 'nodes'),\n",
              " ('O', 'and'),\n",
              " ('O', 'the'),\n",
              " ('O', 'parametrium'),\n",
              " ('O', '.'),\n",
              " ('O', 'revealed'),\n",
              " ('O', 'that'),\n",
              " ('O', 'the'),\n",
              " ('O', 'tumour'),\n",
              " ('O', 'also'),\n",
              " ('O', 'extensively'),\n",
              " ('O', 'involved'),\n",
              " ('O', 'the'),\n",
              " ('O', 'lower'),\n",
              " ('O', 'uterine'),\n",
              " ('O', 'segment'),\n",
              " ('O', '.')]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jeBJwjyaDvyx"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15c2e604bf4e4886821874bb10147554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387328e6a6f3422385b17056f37f3dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39001299f43a4c16bee42f59f065b896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a27ab00e70c48fe8bc6d5750303a598": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fca3082fe64910a906cd82b3b2f20b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728191bf50e8467a8cf4e53bb823a0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6aa34645c404115a825d7c574833a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_99cdbe1ed5ab427bbc70ec32ee0a7d6d",
            "value": " 4.83k/4.83k [00:00&lt;00:00, 188kB/s]"
          }
        },
        "74ef95542b824da48226d4fc3e02efd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7759614498164d92932c932e1bfbfa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "785874a052404f168cb1a56dbead0ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98174d97236745ac9e554df41eaf30f5",
            "max": 265719180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f11add9376f34444abfea63a11e404fb",
            "value": 125829120
          }
        },
        "81d1c305b7f940bd865fed91a7bc5405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fca3082fe64910a906cd82b3b2f20b",
            "placeholder": "​",
            "style": "IPY_MODEL_7759614498164d92932c932e1bfbfa6b",
            "value": "config.json: 100%"
          }
        },
        "8ef0668f8a4e4239b4bb8f46f56922e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9474d4651e924f038fab1e7ddfb6e0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6ec4546b3014b06b76b25a1addb3498",
              "IPY_MODEL_785874a052404f168cb1a56dbead0ec9",
              "IPY_MODEL_99f9abae98c247c598e74fddb74f4a7b"
            ],
            "layout": "IPY_MODEL_b9444bb03ebd465698a10fe41b533018"
          }
        },
        "98174d97236745ac9e554df41eaf30f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cdbe1ed5ab427bbc70ec32ee0a7d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f9abae98c247c598e74fddb74f4a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c2e604bf4e4886821874bb10147554",
            "placeholder": "​",
            "style": "IPY_MODEL_8ef0668f8a4e4239b4bb8f46f56922e1",
            "value": " 126M/266M [00:05&lt;00:05, 24.0MB/s]"
          }
        },
        "a6aa34645c404115a825d7c574833a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ec4546b3014b06b76b25a1addb3498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea147de43154cf7917c35e6a81fe30a",
            "placeholder": "​",
            "style": "IPY_MODEL_387328e6a6f3422385b17056f37f3dfc",
            "value": "model.safetensors:  47%"
          }
        },
        "b2801884cff0451985c0ce64ba752b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81d1c305b7f940bd865fed91a7bc5405",
              "IPY_MODEL_f4ec5dbfbc7642bdaaa501943e0396ba",
              "IPY_MODEL_728191bf50e8467a8cf4e53bb823a0d0"
            ],
            "layout": "IPY_MODEL_39001299f43a4c16bee42f59f065b896"
          }
        },
        "b9444bb03ebd465698a10fe41b533018": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea147de43154cf7917c35e6a81fe30a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11add9376f34444abfea63a11e404fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ec5dbfbc7642bdaaa501943e0396ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a27ab00e70c48fe8bc6d5750303a598",
            "max": 4829,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74ef95542b824da48226d4fc3e02efd1",
            "value": 4829
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
